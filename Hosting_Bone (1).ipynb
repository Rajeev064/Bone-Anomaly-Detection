{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hosting_Bone.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dysBxucQr_pP"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr-JLHdqvQbj"
      },
      "source": [
        "from keras.preprocessing import image        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXcfcctfsXJY"
      },
      "source": [
        "from keras.models import load_model\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPgNDLX2v4r5",
        "outputId": "e59899b2-ec2b-4792-8ed3-e60c6936ec33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy1fWpyU1LdA"
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = '/content/drive/MyDrive/Broner/InceptionResnet/Ml/finalized_model.sav'\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "m = load_model('/content/drive/MyDrive/Broner/model.h5')\n",
        "m1 = load_model('/content/drive/MyDrive/Broner/InceptionResnetv2/0.hdf5')\n",
        "m2 = load_model('/content/drive/MyDrive/Broner/InceptionResnetv2/1.hdf5')\n",
        "m3 = load_model('/content/drive/MyDrive/Broner/InceptionResnetv2/2.hdf5')\n",
        "m4 = load_model('/content/drive/MyDrive/Broner/InceptionResnetv2/3.hdf5')\n",
        "m5 = load_model('/content/drive/MyDrive/Broner/InceptionResnetv2/4.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvAdMyL6o6d0"
      },
      "source": [
        "def check_value(var):\n",
        "  \n",
        "  if var>0.5:\n",
        "    return 1\n",
        "  return 0\n",
        "def new_answer(img):\n",
        "  arr = np.empty(5, dtype=int)\n",
        "  # img = image.load_img(path,target_size=(320,320))\n",
        "  img_tensor = image.img_to_array(img)\n",
        "  img_tensor = np.expand_dims(img_tensor,axis = 0)\n",
        "  img_tensor /= 255\n",
        "  img_tensor[:,:,0] = (img_tensor[:,:,0]-0.485)/0.229\n",
        "  img_tensor[:,:,1] = (img_tensor[:,:,1]-0.456)/0.224\n",
        "  img_tensor[:,:,2] = (img_tensor[:,:,2]-0.406)/0.225\n",
        "  ans1 = m1.predict(img_tensor)\n",
        "  arr[0] = check_value(ans1)\n",
        "  ans2 = m2.predict(img_tensor) \n",
        "  arr[1] = check_value(ans2)\n",
        "  ans3 = m3.predict(img_tensor)\n",
        "  arr[2] = check_value(ans3)\n",
        "  ans4 = m4.predict(img_tensor)\n",
        "  arr[3] = check_value(ans4)\n",
        "  ans5 = m5.predict(img_tensor)\n",
        "  arr[4] = check_value(ans5)\n",
        "  arr = arr.reshape(1,-1)\n",
        "  ans = m.predict(img_tensor)\n",
        "  a = np.argmax(ans)\n",
        "  if a == 0:\n",
        "    bone = 'Shoulder'\n",
        "  elif a == 1:\n",
        "    bone = 'Humerus' \n",
        "  else:\n",
        "    bone = 'Forearm'\n",
        "  # print(loaded_model.predict(arr))\n",
        "  return loaded_model.predict(arr),bone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_gf8pg9qmYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac26bbb-eb8a-4c56-e0de-175b41eb9220"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tYro-cy9Yu0"
      },
      "source": [
        "import numpy\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import Model\n",
        "from keras.preprocessing import image \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "def grad_cam(model, img_tensor,\n",
        "             layer_name=\"conv_7b_ac\", label_name=None,\n",
        "             category_id=None):\n",
        "    \"\"\"Get a heatmap by Grad-CAM.\n",
        "    Args:\n",
        "        model: A model object, build from tf.keras 2.X.\n",
        "        img: An image ndarray.\n",
        "        layer_name: A string, layer name in model.\n",
        "        label_name: A list,\n",
        "            show the label name by assign this argument,\n",
        "            it should be a list of all label names.\n",
        "        category_id: An integer, index of the class.\n",
        "            Default is the category with the highest score in the prediction.\n",
        "    Return:\n",
        "        A heatmap ndarray(without color).\n",
        "    \"\"\"\n",
        "    heatmap_model = Model([model.inputs], [model.get_layer(layer_name).output , model.output])\n",
        "    with tf.GradientTape() as gtape:\n",
        "        conv_output, predictions = heatmap_model(img_tensor)\n",
        "        if category_id == None:\n",
        "            if predictions[0]<0.5:\n",
        "              category_id = 0\n",
        "            else:\n",
        "              category_id = 1\n",
        "        if label_name:\n",
        "            print(label_name[category_id])\n",
        "        output = predictions[:,0]\n",
        "        grads = gtape.gradient(output, conv_output)\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    max_heat = np.max(heatmap)\n",
        "    if max_heat == 0:\n",
        "        max_heat = 1e-10\n",
        "    heatmap /= max_heat\n",
        "\n",
        "    return np.squeeze(heatmap)\n",
        "\n",
        "def grad_cam_plus(model, img_tensor,\n",
        "                  layer_name=\"conv_7b_ac\", label_name=None,\n",
        "                  category_id=None):\n",
        "    \"\"\"Get a heatmap by Grad-CAM.\n",
        "    Args:\n",
        "        model: A model object, build from tf.keras 2.X.\n",
        "        img: An image ndarray.\n",
        "        layer_name: A string, layer name in model.\n",
        "        label_name: A list,\n",
        "            show the label name by assign this argument,\n",
        "            it should be a list of all label names.\n",
        "        category_id: An integer, index of the class.\n",
        "            Default is the category with the highest score in the prediction.\n",
        "    Return:\n",
        "        A heatmap ndarray(without color).\n",
        "    \"\"\"\n",
        "    conv_layer = model.get_layer(layer_name)\n",
        "    heatmap_model = Model([model.inputs], [conv_layer.output, model.output])\n",
        "\n",
        "    with tf.GradientTape() as gtape1:\n",
        "        with tf.GradientTape() as gtape2:\n",
        "            with tf.GradientTape() as gtape3:\n",
        "                conv_output, predictions = heatmap_model(img_tensor)\n",
        "                if category_id==None:\n",
        "                    if predictions[0]<0.5:\n",
        "                      category_id = 0\n",
        "                    else:\n",
        "                      category_id = 1\n",
        "                if label_name:\n",
        "                    print(label_name[category_id])\n",
        "                output = predictions[:,0]\n",
        "                conv_first_grad = gtape3.gradient(output, conv_output)\n",
        "            conv_second_grad = gtape2.gradient(conv_first_grad, conv_output)\n",
        "        conv_third_grad = gtape1.gradient(conv_second_grad, conv_output)\n",
        "\n",
        "    global_sum = np.sum(conv_output, axis=(0, 1, 2))\n",
        "\n",
        "    alpha_num = conv_second_grad[0]\n",
        "    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum\n",
        "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, 1e-10)\n",
        "    \n",
        "    alphas = alpha_num/alpha_denom\n",
        "    alpha_normalization_constant = np.sum(alphas, axis=(0,1))\n",
        "    alphas /= alpha_normalization_constant\n",
        "\n",
        "    weights = np.maximum(conv_first_grad[0], 0.0)\n",
        "\n",
        "    deep_linearization_weights = np.sum(weights*alphas, axis=(0,1))\n",
        "    grad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n",
        "\n",
        "    heatmap = np.maximum(grad_CAM_map, 0)\n",
        "    max_heat = np.max(heatmap)\n",
        "    if max_heat == 0:\n",
        "        max_heat = 1e-10\n",
        "    heatmap /= max_heat\n",
        "\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JK0D-xE9kXj"
      },
      "source": [
        "def find_target_layer(model):\n",
        "\t\t# attempt to find the final convolutional layer in the network\n",
        "\t\t# by looping over the layers of the network in reverse order\n",
        "\t\tfor layer in reversed(model.layers):\n",
        "\t\t\t# check to see if the layer has a 4D output\n",
        "\t\t\tif len(layer.output_shape) == 4:\n",
        "\t\t\t\treturn layer.name\n",
        "\t\t# otherwise, we could not find a 4D layer so the GradCAM\n",
        "\t\t# algorithm cannot be applied\n",
        "\t\traise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqfYxeDE9kqZ"
      },
      "source": [
        "def show_imgwithheat(img_path, heatmap, alpha=0.4, return_array=True):\n",
        "    \"\"\"Show the image with heatmap.\n",
        "    Args:\n",
        "        img_path: string.\n",
        "        heatmap:  image array, get it by calling grad_cam().\n",
        "        alpha:    float, transparency of heatmap.\n",
        "        return_array: bool, return a superimposed image array or not.\n",
        "    Return:\n",
        "        None or image array.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(img_path)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = (heatmap*255).astype(\"uint8\")\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = heatmap * alpha + img\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(\"uint8\")\n",
        "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    imgwithheat = Image.fromarray(superimposed_img) \n",
        "    # imgwithheat.save('/content/drive/MyDrive/static/heat.jpg') \n",
        "    # plt.imshow(imgwithheat)\n",
        "    # return imgwithheat\n",
        "    if return_array:\n",
        "        return superimposed_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TASeFi8Z-sI5"
      },
      "source": [
        "def preprocess(img):\n",
        "  resized = cv2.resize(img, (320,320))\n",
        "  img_tensor = image.img_to_array(resized)\n",
        "  img_tensor = np.expand_dims(img_tensor,axis = 0)\n",
        "  img_tensor /= 255\n",
        "  img_tensor[:,:,0] = (img_tensor[:,:,0]-0.485)/0.229\n",
        "  img_tensor[:,:,1] = (img_tensor[:,:,1]-0.456)/0.224\n",
        "  img_tensor[:,:,2] = (img_tensor[:,:,2]-0.406)/0.225\n",
        "  return img_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqaKyJX7-D4T",
        "outputId": "f7374aed-4069-4fc3-eaba-2b317e21da8a"
      },
      "source": [
        "img_path = '/content/drive/MyDrive/Broner/MURA-v1.1/train/XR_HUMERUS/patient00051/study1_positive/image1.png'\n",
        "img = cv2.imread(img_path)\n",
        "img = preprocess(img)\n",
        "heatmap_plus = grad_cam_plus(m4, img , label_name=['Negative' , 'Positive'])\n",
        "show_imgwithheat(img_path, heatmap_plus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[102,  97,   0],\n",
              "        [102,  97,   0],\n",
              "        [102,  97,   0],\n",
              "        ...,\n",
              "        [ 67,  67, 161],\n",
              "        [ 68,  68, 162],\n",
              "        [ 67,  67, 161]],\n",
              "\n",
              "       [[102,  97,   0],\n",
              "        [102,  97,   0],\n",
              "        [102,  97,   0],\n",
              "        ...,\n",
              "        [ 68,  68, 162],\n",
              "        [ 67,  67, 161],\n",
              "        [ 67,  67, 161]],\n",
              "\n",
              "       [[102,  97,   0],\n",
              "        [102,  97,   0],\n",
              "        [102,  97,   0],\n",
              "        ...,\n",
              "        [ 66,  66, 160],\n",
              "        [ 67,  67, 161],\n",
              "        [ 67,  67, 161]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[151, 166,  79],\n",
              "        [152, 167,  80],\n",
              "        [153, 168,  81],\n",
              "        ...,\n",
              "        [  0,   0, 100],\n",
              "        [  0,   0, 100],\n",
              "        [  0,   0, 100]],\n",
              "\n",
              "       [[153, 168,  81],\n",
              "        [153, 168,  81],\n",
              "        [151, 166,  79],\n",
              "        ...,\n",
              "        [  0,   0, 100],\n",
              "        [  0,   0, 100],\n",
              "        [  0,   0, 100]],\n",
              "\n",
              "       [[152, 167,  80],\n",
              "        [151, 166,  79],\n",
              "        [152, 167,  80],\n",
              "        ...,\n",
              "        [  0,   0, 100],\n",
              "        [  0,   0, 100],\n",
              "        [  0,   0, 100]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxsfjVd60_m0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e79c34-d3a5-43cc-99ca-257692998b61"
      },
      "source": [
        "from flask import Flask,render_template,request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import cv2,base64,re\n",
        "import werkzeug\n",
        "import keras.models\n",
        "app = Flask(__name__,template_folder='/content/drive/MyDrive/templates',static_folder='/content/drive/MyDrive/static')\n",
        "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n",
        "run_with_ngrok(app)   \n",
        "# app.debug = True\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template('index.html',link = 'left.jpg')\n",
        "\n",
        "\n",
        "@app.route(\"/image\",methods=['POST','GET'])\n",
        "def answers():\n",
        "  link = 'left.jpg'\n",
        "  if request.method == 'POST':\n",
        "    imagefile = request.files['img']\n",
        "    filename = 'temp.jpg'\n",
        "    print(\"\\nReceived image File name : \" + imagefile.filename)\n",
        "    imagefile.save(filename)\n",
        "    \n",
        "    img = cv2.imread(filename)\n",
        "    resized = cv2.resize(img, (320,320))\n",
        "    heat = preprocess(resized)\n",
        "    heatmap_plus = grad_cam(m4,heat , label_name=['Negative' , 'Positive'])\n",
        "    arr = show_imgwithheat('temp.jpg', heatmap_plus) \n",
        "    # arr.save('/content/drive/MyDrive/static/heat.jpg') \n",
        "    cv2.imwrite('/content/drive/MyDrive/static/heat.jpg',arr)\n",
        "    cv2.imwrite('heat.jpg',arr)\n",
        "    result,bone = new_answer(resized)\n",
        "    if result[0] == 0:\n",
        "      rs = 'negative'\n",
        "    else:\n",
        "      rs = 'positive'\n",
        "    return render_template('index.html',results = rs,bone = bone,link = 'heat.jpg')\n",
        "  else:\n",
        "    return render_template('index.html',link = link)\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://c34c1f35d338.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [30/Apr/2021 11:01:02] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:02] \"\u001b[37mGET /static/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:02] \"\u001b[37mGET /static/left.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:04] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:04] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:06] \"\u001b[37mGET /static/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:06] \"\u001b[37mGET /static/left.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Received image File name : image1.png\n",
            "Positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [30/Apr/2021 11:01:09] \"\u001b[37mGET /image HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:10] \"\u001b[37mGET /static/left.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:10] \"\u001b[37mGET /static/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:14] \"\u001b[37mPOST /image HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:14] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
            "127.0.0.1 - - [30/Apr/2021 11:01:14] \"\u001b[37mGET /static/heat.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL0ibKlP0970"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-tfFN-Z02dU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xWzuf-P00Sb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFGl2mJc0xq-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itw_XKzh0uMg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F4g0s460Hoj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfW41T-f0EJV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2l0-tKvz_xw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSoRGbi6zk1k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATPx1K14zGC9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLYoSzDbyW2U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyNmei9EyQ8r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAl034qwueOb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GB5S7WktdEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjN3WZNztZhx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkZnOB-3syYk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}